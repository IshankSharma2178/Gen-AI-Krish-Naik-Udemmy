{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e65eac7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import ArxivQueryRun,WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper,ArxivAPIWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5898d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_wrapper=ArxivAPIWrapper(arxiv_search=<class 'arxiv.Search'>, arxiv_exceptions=(<class 'arxiv.ArxivError'>, <class 'arxiv.UnexpectedEmptyPageError'>, <class 'arxiv.HTTPError'>), top_k_results=2, ARXIV_MAX_QUERY_LENGTH=300, continue_on_failure=False, load_max_docs=100, load_all_available_meta=False, doc_content_chars_max=500)\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_arxiv = ArxivAPIWrapper(top_k_results=2,doc_content_chars_max=500)\n",
    "arxiv = ArxivQueryRun(api_wrapper=api_wrapper_arxiv)\n",
    "print(arxiv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb92f36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Published: 2024-07-22\\nTitle: Attention Is All You Need But You Don't Need All Of It For Inference of Large Language Models\\nAuthors: Georgy Tyukin, Gbetondji J-S Dovonon, Jean Kaddour, Pasquale Minervini\\nSummary: The inference demand for LLMs has skyrocketed in recent months, and serving\\nmodels with low latencies remains challenging due to the quadratic input length\\ncomplexity of the attention layers. In this work, we investigate the effect of\\ndropping MLP and attention layers at inference time o\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv.invoke(\"Attention is all you need\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d0ee21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_wrapper=WikipediaAPIWrapper(wiki_client=<module 'wikipedia' from 'e:\\\\GenAi\\\\AgenticAIWorkspace\\\\venv\\\\lib\\\\site-packages\\\\wikipedia\\\\__init__.py'>, top_k_results=1, lang='en', load_all_available_meta=False, doc_content_chars_max=500)\n"
     ]
    }
   ],
   "source": [
    "api_wrapper_wiki = WikipediaAPIWrapper(top_k_results=1,doc_content_chars_max=500)\n",
    "wiki = WikipediaQueryRun(api_wrapper=api_wrapper_wiki)\n",
    "print(wiki)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "04f2465a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: Standard ML\\nSummary: Standard ML (SML) is a general-purpose, high-level, modular, functional programming language with compile-time type checking and type inference. It is popular for writing compilers, for programming language research, and for developing theorem provers.\\nStandard ML is a modern dialect of ML, the language used in the Logic for Computable Functions (LCF) theorem-proving project. It is distinctive among widely used languages in that it has a formal specification, given as '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki.invoke(\"What is ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "26974432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"ReAct-agent\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "845c90aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tavily = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0424b774",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Standards News Highlights - API',\n",
       "  'url': 'https://www.api.org/products-and-services/standards/important-standards-announcements',\n",
       "  'content': 'February 4, 2025 – The American Petroleum Institute (API) today released a new report, 2025 API StandardsInternational Usage Report, detailing the growing international influence of API standards. The report identifies where governments and standards bodies reference API standards in policies, national and international standards, and technical regulations, highlighting the paramount role of API standards in advancing safety, sustainability, and efficiency across the global natural gas and oil [...] February 4, 2025 – The American Petroleum Institute (API) today released a new report, 2025 API StandardsInternational Usage Report, detailing the growing international influence of API standards. The report identifies where governments and standards bodies reference API standards in policies, national and international standards, and technical regulations, highlighting the paramount role of API standards in advancing safety, sustainability, and efficiency across the global natural gas and oil [...] September 5, 2024 - The American Petroleum Institute (API) today announced the publication of Addendum 2 to API 6D, 25th Edition: Specifications for Valves. This update introduces important new provisions that address the unique challenges associated with hydrogen gas service, underscoring the industry’s ongoing commitment to safety and innovation.',\n",
       "  'score': 0.72465646},\n",
       " {'title': 'API Statement on EPA Proposal to Repeal Vehicle Emissions ...',\n",
       "  'url': 'https://www.api.org/news-policy-and-issues/news/2025/07/29/api-statement-on-epa-proposal-to-repeal-vehicle-emissions-standards',\n",
       "  'content': 'WASHINGTON, July 29, 2025 — American Petroleum Institute (API) President and CEO Mike Sommers issued the following statement after the Environmental Protection Agency announced a proposal to repeal the Biden administration\\'s tailpipe emissions standards and restore consumer choice. The rules—previously challenged by API in court—would have eliminated most new gas cars and traditional hybrids from the U.S. market in less than a decade. [...] ###\\n\\n#### Related Topics:\\n\\n#### Other Resources:\\n\\n## Sign Up for Updates\\n\\n## Stay Connected\\n\\n##### API Energy\\n\\n##### API Global\\n\\n## X Feed\\n\\nAmerican Petroleum Institute\\n\\n#### Oil & Natural Gas\\n\\n#### Products & Services\\n\\n#### News, Policy & Issues\\n\\n© Copyright 2025 - API. All Rights Reserved. | Terms & Conditions | Privacy\\n\\n© Copyright 2025 - API. All Rights Reserved. | Terms & Conditions | Privacy [...] \"We support Administrator Zeldin\\'s proposal to repeal the Biden administration\\'s costly and unrealistic tailpipe rules, which would have effectively banned new gas-powered vehicles. This is a critical step toward restoring consumer choice and protecting the freedom of all Americans to decide what they drive. We look forward to working with the administration on policies that help reduce emissions while ensuring reliable and affordable transportation options for consumers.\"',\n",
       "  'score': 0.6633424},\n",
       " {'title': 'API Applauds Interior Action to Support Production on Federal Lands',\n",
       "  'url': 'https://www.api.org/news-policy-and-issues/news/2025/07/07/api-applauds-interior-action-to-support-production-on-federal-lands',\n",
       "  'content': 'Energy API\\nAmerican Petroleum Institute\\n\\n# API Applauds Interior Action to Support Production on Federal Lands\\n\\n202.682.8114 | press@api.org\\n\\nWASHINGTON, July 7, 2025 — American Petroleum Institute (API) Vice President of Upstream Policy Holly Hopkins released the following statement after the Department of the Interior announced a new commingling policy to safely increase production while enhancing resource conservation on federal lands: [...] ###\\n\\n#### Related Topics:\\n\\n#### Other Resources:\\n\\n## Sign Up for Updates\\n\\n## Stay Connected\\n\\n##### API Energy\\n\\n##### API Global\\n\\n## X Feed\\n\\nAmerican Petroleum Institute\\n\\n#### Oil & Natural Gas\\n\\n#### Products & Services\\n\\n#### News, Policy & Issues\\n\\n© Copyright 2025 - API. All Rights Reserved. | Terms & Conditions | Privacy\\n\\n© Copyright 2025 - API. All Rights Reserved. | Terms & Conditions | Privacy [...] \"We applaud Secretary Burgum’s action to further unleash our nation’s vast resources in support of U.S. energy dominance. We look forward to engaging with Interior to leverage new technologies to support more efficient and responsible oil and natural gas production on federal lands.”',\n",
       "  'score': 0.595987},\n",
       " {'title': 'July 28, 2025: Suspicious shipments of API continue to be sent to ...',\n",
       "  'url': 'https://www.safemedicines.org/2025/07/july-28-2025.html',\n",
       "  'content': 'Partnership for Safe Medicines\\n\\n# July 28, 2025: Suspicious shipments of API continue to be sent to buyers in the U.S.\\n\\n## Major Stories [...] Keep up with state legislation in the areas of pill presses, prescription drug affordability boards, and drug importation.\\n\\n### Patient safety issues in the GLP-1 space this week\\n\\nOn July 18th, a Reddit user shared that they were sent the wrong medication. Instead of receiving tirzepatide, the Reddit user received sermorelin, a synthetic form of growth hormone-releasing hormone.\\n\\nReddit post, July 18, 2025\\n\\n## International News [...] PSM published this report on the same day that it was reported that Eli Lilly would no longer be partnering with Noom to sell Zepbound and Mounjaro. Noom continued to market a compounded version of tirzepatide, which Eli Lilly stated was in violation to companies’ agreement.\\n\\nJune fishy freight thumbnail\\n\\nClick the image to read the newest report.\\n\\n## Domestic News\\n\\nCongressmembers urge FDA to act and leader of drug trafficking ring sentenced in Florida.',\n",
       "  'score': 0.4866005},\n",
       " {'title': 'API Monogram, Repair and Remanufacture and APIQR: Latest ...',\n",
       "  'url': 'https://www.api.org/products-and-services/api-monogram-and-apiqr/latest-updates',\n",
       "  'content': 'American Petroleum Institute\\n\\n#### Oil & Natural Gas\\n\\n#### Products & Services\\n\\n#### News, Policy & Issues\\n\\n© Copyright 2025 - API. All Rights Reserved. | Terms & Conditions | Privacy\\n\\n© Copyright 2025 - API. All Rights Reserved. | Terms & Conditions | Privacy [...] Energy API\\nAmerican Petroleum Institute\\n\\n# API Monogram, Repair and Remanufacture and APIQR: Latest Updates\\n\\nAPI provides courtesy Addenda and Errata documents for the API specifications that are part of the Monogram and Repair and Remanufacture Programs. You will also find copies here of notifications concerning program and specification updates. [...] #### API 20F - Corrosion-resistant Bolting for Use in the Petroleum and Natural Gas Industries\\n\\n#### API 547 - General Purpose Form-wound Squirrel Cage Induction Motors—185 kW (250 hp) through 2240 kW (3000 hp)\\n\\n#### API 594 - Check Valves\\n\\n#### API 600 - Steel Gate Valves-Flanged and Butt-Welding Ends, Bolted Bonnets\\n\\n#### API 602 - Gate, Globe, and Check Valves for Sizes DN 100 (NPS 4) and Smaller…\\n\\n#### API 603 - Corrosion-Resistant, Bolted Bonnet Gate Valves-Flanged and…',\n",
       "  'score': 0.4069804}]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tavily.invoke(\"Provide me the recent API news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f1ba1a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def divide(a: int, b: int) -> float:\n",
    "    \"\"\"Divide two integers.\"\"\"\n",
    "    return a / b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "84b823cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [arxiv, wiki, tavily, multiply, add, divide]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80a77f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(model=\"gemma2-9b-it\")\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "29e6b55b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'tavily_search_results_json',\n",
       "  'args': {'query': 'recent AI news'},\n",
       "  'id': '0g92xhymf',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from langchain_core.messages import AIMessage,HumanMessage\n",
    "\n",
    "llm_with_tools.invoke([HumanMessage(content=f\"What is recent AI news\")]).tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "adb99b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import TypedDict\n",
    "from langchain_core.messages import AnyMessage\n",
    "from typing import Annotated\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages : Annotated[list[AnyMessage],add_messages] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "370bc222",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Entire Chatbot With LangGraph\n",
    "from IPython.display import Image, display\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "\n",
    "### Node definition\n",
    "def tool_calling_llm(state:State):\n",
    "    return {\"messages\":[llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Build graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from assistant is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from assistant is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    ")\n",
    "builder.add_edge(\"tools\",\"tool_calling_llm\")\n",
    "\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# View\n",
    "# display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aaf11f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "1706.03762\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  arxiv (e5v0gjpz9)\n",
      " Call ID: e5v0gjpz9\n",
      "  Args:\n",
      "    query: 1706.03762\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: arxiv\n",
      "\n",
      "Published: 2023-08-02\n",
      "Title: Attention Is All You Need\n",
      "Authors: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, Illia Polosukhin\n",
      "Summary: The dominant sequence transduction models are based on complex recurrent or\n",
      "convolutional neural networks in an encoder-decoder configuration. The best\n",
      "performing models also connect the encoder and decoder through an attention\n",
      "mechanism. We propose a new simple network architecture, the Transformer, base\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (6kmtvka59)\n",
      " Call ID: 6kmtvka59\n",
      "  Args:\n",
      "    query: Transformer (machine learning)\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: Transformer (deep learning architecture)\n",
      "Summary: In deep learning, transformer is an architecture based on the multi-head attention mechanism, in which text is converted to numerical representations called tokens, and each token is converted into a vector via lookup from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism, allowing the signal for key token\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Transformer is a novel neural network architecture that relies heavily on attention mechanisms.  \n",
      "\n",
      "It was introduced in the 2017 paper \"Attention Is All You Need\" and has since revolutionized natural language processing tasks. \n",
      "\n",
      "Traditional sequence transduction models often used recurrent or convolutional networks, but the Transformer's attention-based design proved to be more efficient and effective.\n",
      "\n",
      "\n",
      "\n",
      "Let me know if you'd like more details about any specific aspect of the Transformer!\n"
     ]
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\":HumanMessage(content=\"1706.03762\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "34f69a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Provide me the top 10 recent AI news for MArch 3rd 2025 , add 5 plus 5 and then multiply by 10\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (s761s8aa1)\n",
      " Call ID: s761s8aa1\n",
      "  Args:\n",
      "    query: Top 10 recent AI news for March 3rd 2025\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: OpenAI\n",
      "Summary: OpenAI, Inc. is an American artificial intelligence (AI) organization founded in December 2015 and headquartered in San Francisco, California. It aims to develop \"safe and beneficial\" artificial general intelligence (AGI), which it defines as \"highly autonomous systems that outperform humans at most economically valuable work\". As a leading organization in the ongoing AI boom, OpenAI is known for the GPT family of large language models, the DALL-E series of text-to-image mo\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (tyxwtga1a)\n",
      " Call ID: tyxwtga1a\n",
      "  Args:\n",
      "    a: 10\n",
      "    b: 15\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "150\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\":HumanMessage(content=\"Provide me the top 10 recent AI news for MArch 3rd 2025 , add 5 plus 5 and then multiply by 10\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1365c693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What is machine learning\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  wikipedia (97awx04sb)\n",
      " Call ID: 97awx04sb\n",
      "  Args:\n",
      "    query: machine learning\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: wikipedia\n",
      "\n",
      "Page: Machine learning\n",
      "Summary: Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions. Within a subdiscipline in machine learning, advances in the field of deep learning have allowed neural networks, a class of statistical algorithms, to surpass many previous machine learning approaches in performance.\n",
      "ML fi\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalise to unseen data, and thus perform tasks without explicit instructions.\n"
     ]
    }
   ],
   "source": [
    "messages=graph.invoke({\"messages\":HumanMessage(content=\"What is machine learning\")})\n",
    "for m in messages['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04cbb50",
   "metadata": {},
   "source": [
    "### Agent Memory\n",
    "\n",
    "Aim \n",
    "\n",
    "let introduce agent with memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e8fac",
   "metadata": {},
   "source": [
    "#### MemorySaver\n",
    "LangGraph can use a checkpointer to automatically save the graph state after each step.\n",
    "\n",
    "This built-in persistence layer gives us memory, allowing LangGraph to pick up from the last state update.\n",
    "\n",
    "One of the easiest checkpointers to use is the MemorySaver, an in-memory key-value store for Graph state.\n",
    "\n",
    "All we need to do is simply compile the graph with a checkpointer, and our graph has memory!\n",
    "\n",
    "![image.png](attachment:image.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cb49c528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tool_calling_llm': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'ay2xye85s', 'function': {'arguments': '{\"a\":3,\"b\":5}', 'name': 'add'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 87, 'prompt_tokens': 1646, 'total_tokens': 1733, 'completion_time': 0.158181818, 'prompt_time': 0.031105962, 'queue_time': 0.257843488, 'total_time': 0.18928778}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run--243afdc2-5348-4cee-b8b8-78c438c72cbb-0', tool_calls=[{'name': 'add', 'args': {'a': 3, 'b': 5}, 'id': 'ay2xye85s', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1646, 'output_tokens': 87, 'total_tokens': 1733})]}}\n",
      "{'tools': {'messages': [ToolMessage(content='8', name='add', id='b171e1f3-80d6-48d1-bcce-c0610c089e79', tool_call_id='ay2xye85s')]}}\n",
      "{'tool_calling_llm': {'messages': [AIMessage(content='8', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 3, 'prompt_tokens': 1723, 'total_tokens': 1726, 'completion_time': 0.005454545, 'prompt_time': 0.03233354, 'queue_time': 0.25662721, 'total_time': 0.037788085}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--01c149e3-ac4a-4a06-8a6a-45f60c720fb9-0', usage_metadata={'input_tokens': 1723, 'output_tokens': 3, 'total_tokens': 1726})]}}\n"
     ]
    }
   ],
   "source": [
    "stream = graph.stream({\"messages\": [HumanMessage(content=\"Add 3 and 5\")]})\n",
    "for output in stream:\n",
    "    print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89991bef",
   "metadata": {},
   "source": [
    "#### MemorySaver\n",
    "LangGraph can use a checkpointer to automatically save the graph state after each step.\n",
    "\n",
    "This built-in persistence layer gives us memory, allowing LangGraph to pick up from the last state update.\n",
    "\n",
    "One of the easiest checkpointers to use is the MemorySaver, an in-memory key-value store for Graph state.\n",
    "\n",
    "All we need to do is simply compile the graph with a checkpointer, and our graph has memory!\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e4991",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
